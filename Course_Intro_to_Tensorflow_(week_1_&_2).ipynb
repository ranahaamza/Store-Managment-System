{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course: Intro to Tensorflow (week 1 & 2)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9DiAPnpcyAYpDlSQC4cw8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranahaamza/Store-Managment-System/blob/main/Course_Intro_to_Tensorflow_(week_1_%26_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8e-if6pIlbS",
        "outputId": "299450f1-92b3-449c-adb2-c7e536fb1392"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "import numpy as np\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7J85kzkGc1d"
      },
      "source": [
        "# Week 1: A New Programming Paradigm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWhmf7eFX3r"
      },
      "source": [
        "# Keras make easy to learn define neural networks.\n",
        "# A neural network is a set of functions which can learn patterns. \n",
        "# below code is written using Python and TensorFlow and an API in TensorFlow called keras.\n",
        "\n",
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "# 'Dense' is used to define a layer of connected neurons, there is onle 1 Dense here mean there's only 1 layer here.\n",
        "# 1 'unit' mean 1 neuron here.\n",
        "# successive layers are defined in sequence, hence the word 'Sequential'.\n",
        "# 'input_shape=1' mean our input has only 1 value"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E96l33cwI9gU"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error') # optimizer and loss are fuctions\n",
        "\n",
        "# Optimizer: for new guess (use the optimizer to generate a new guess and repeat).\n",
        "# Loss: Loss measure how well or how badly it did using the loss function \n",
        "# Goal of these functions is to make a guess as to what the relationship is between the input data and the output data\n",
        "\n",
        "# The neural network has no idea of the relationship between X and Y, so it makes a guess. Say it guesses Y equals 10X minus 10. It will then use the data that it knows about, that's the set of Xs and Ys that we've already seen to measure how good or how bad its guess was. The loss function measures this and then gives the data to the optimizer which figures out the next guess. \n",
        "# the loss function measures this and then gives the data to the optimizer which figures out the next guess.\n",
        "# so the optimizer thinks about how good or how badly guess was done using the data from the Loss Function.\n",
        "# logic is that each guess should be better than the one before, As the guesses get better and better an accuracy approaches 100%.\n",
        "\n",
        "# In this case 'loss' is mean square error and 'optimer' is SGD(Stochastic Gradient Descent)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YF6FGQlJAIb",
        "outputId": "f9235062-2a46-4db5-8ca9-a9c6f2e7f9e3"
      },
      "source": [
        "# deine and compile the neural network\n",
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error') # optimizer and loss are fuctions\n",
        "\n",
        "# providing the data\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float) # y=2x-1\n",
        "\n",
        "# trining the neural network\n",
        "model.fit(xs, ys, epochs=500) # epochs=500 mean that it will go through the training loop 500 times.\n",
        "# this training loop is what we describe earlier. Make a guess, measure how good or how bad the guesses with the loss function, then use the optimizer and the data to make another guess and repeat this.\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 2.1574\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8433\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5931\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3934\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2334\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1047\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0007\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.9161\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8470\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7900\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7426\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7028\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6691\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6402\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6151\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5931\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5735\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5559\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5399\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5252\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5116\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4989\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4869\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4755\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4647\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4543\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4443\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4346\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4253\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4162\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4074\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3988\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3905\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3823\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3744\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3666\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3590\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3516\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3443\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3372\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3303\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3235\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3168\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3103\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3039\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2977\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2915\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2856\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2797\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2739\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2683\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2628\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2574\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2521\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2469\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2419\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2369\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2320\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2273\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2226\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2180\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2135\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2091\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2049\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2006\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1965\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1925\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1885\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1847\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1809\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1772\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1735\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1699\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1665\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1630\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1597\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1564\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1532\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1500\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1470\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1439\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1410\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1381\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1353\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1325\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1298\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1271\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1245\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1219\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1194\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1170\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1146\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1122\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1099\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1077\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1054\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1033\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1012\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0991\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0970\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0950\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0931\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0912\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0893\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0875\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0857\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0839\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0822\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0805\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0789\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0772\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0756\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0741\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0726\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0711\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0696\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0682\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0668\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0654\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0641\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0628\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0615\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0602\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0590\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0578\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0566\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0554\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0543\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0532\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0521\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0510\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0499\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0489\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0479\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0469\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0460\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0450\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0441\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0432\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0423\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0414\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0406\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0398\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0389\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0381\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0374\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0366\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0358\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0351\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0344\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0337\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0330\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0323\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0316\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0310\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0304\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0297\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0291\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0285\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0279\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0274\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0268\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0262\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0257\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0252\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0247\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0242\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0237\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0232\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0227\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0222\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0218\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0209\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0205\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0196\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0188\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0184\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0181\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0177\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0173\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0170\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0166\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0163\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0160\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0156\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0153\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0150\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0147\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0144\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0141\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0138\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0135\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0132\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0130\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0124\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0122\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0117\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0114\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0112\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0110\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0108\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0105\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0103\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0101\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0099\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0097\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0095\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0093\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0091\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0089\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0087\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0086\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0084\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0082\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0080\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0074\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0072\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0071\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0068\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0067\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0065\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0064\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0063\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0061\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0060\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0059\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0057\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0055\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0054\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0053\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0052\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0050\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0049\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0048\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0047\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0044\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0043\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0042\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0041\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0041\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0039\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0038\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0037\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0037\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0036\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0035\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0034\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0034\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0032\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0032\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0031\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0030\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0028\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0027\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0027\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0026\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0025\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0022\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0022\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0020\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0019\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0018\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0018\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0017\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0016\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0015\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0013\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.8844e-04\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6814e-04\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4826e-04\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2878e-04\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0970e-04\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.9101e-04\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7271e-04\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5478e-04\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3723e-04\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2003e-04\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0318e-04\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8668e-04\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7052e-04\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5470e-04\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3920e-04\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2401e-04\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0914e-04\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9457e-04\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8031e-04\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6633e-04\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5265e-04\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3924e-04\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2611e-04\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1325e-04\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0065e-04\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8831e-04\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7623e-04\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6439e-04\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5280e-04\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4145e-04\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3033e-04\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1943e-04\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0876e-04\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9831e-04\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8807e-04\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7805e-04\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6823e-04\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5861e-04\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4919e-04\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3996e-04\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3093e-04\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2208e-04\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1341e-04\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0492e-04\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9660e-04\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8845e-04\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8047e-04\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7266e-04\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6500e-04\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.5751e-04\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5016e-04\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4297e-04\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.3593e-04\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.2903e-04\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2227e-04\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1565e-04\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0917e-04\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0282e-04\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9660e-04\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9050e-04\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8454e-04\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7869e-04\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7297e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6736e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6187e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5649e-04\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5122e-04\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4606e-04\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4101e-04\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3606e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3121e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2646e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2181e-04\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1725e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1279e-04\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0842e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0414e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9994e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9584e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9181e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8787e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8401e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8023e-04\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7653e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7291e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6936e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6588e-04\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.6247e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5913e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5586e-04\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5266e-04\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4953e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4645e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4345e-04\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4050e-04\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3761e-04\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3479e-04\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3202e-04\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2931e-04\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2665e-04\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2405e-04\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2150e-04\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1900e-04\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1656e-04\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1417e-04\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1182e-04\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0953e-04\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0728e-04\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0507e-04\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0291e-04\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0080e-04\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.8731e-05\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.6703e-05\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.4716e-05\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.2771e-05\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0865e-05\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8998e-05\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7170e-05\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5380e-05\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3627e-05\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1908e-05\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.0226e-05\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8579e-05\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.6964e-05\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5383e-05\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3835e-05\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2319e-05\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0833e-05\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9379e-05\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7954e-05\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6557e-05\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5191e-05\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3852e-05\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2541e-05\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1256e-05\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9997e-05\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8765e-05\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7558e-05\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6375e-05\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5216e-05\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4082e-05\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2972e-05\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1884e-05\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0818e-05\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9774e-05\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8751e-05\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7750e-05\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6769e-05\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5809e-05\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4867e-05\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3946e-05\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.3044e-05\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2160e-05\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1293e-05\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0446e-05\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9615e-05\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8801e-05\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8004e-05\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7224e-05\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6459e-05\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5710e-05\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4977e-05\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4258e-05\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3555e-05\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2866e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2190e-05\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1529e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0881e-05\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0246e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9626e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9017e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8421e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7838e-05\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7266e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6706e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6157e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5620e-05\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5094e-05\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4578e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4074e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89c75248d0>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaQm_uwSkXOv",
        "outputId": "443ee649-1c3d-4afd-ce62-bb73f0f8fbec"
      },
      "source": [
        "model.predict([10.0])\n",
        "\n",
        "# x=10, y=2x-1 mean 2(10)-1 = 19\n",
        "# answer is not exact 19 beacuse of small train dataset"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18.985683]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGbecs9k8_8E"
      },
      "source": [
        "# Week 2: Intro to Computer Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_fR_99-_jOc"
      },
      "source": [
        "# now applying previous paradigm for recognizing clothes from labeled value.\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri4U0s-S6pl7",
        "outputId": "73dd92a2-a662-4c15-df95-09916a646174"
      },
      "source": [
        "# writing code to loding training dataset\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist # fashion_mnist is a dataset with an API call in tensorflow. In fashion_mnist dataset 60k-70k data used for trainig and 10k for testing,\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() # .load_data method will return 4 things to us, 1. traning_data, 2. training_set, 3. testing_data, 4. testing_set"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_HS-z5A07Ct"
      },
      "source": [
        "# Coding a computer vision neural network\n",
        "# Now in sequential there's 3 layers\n",
        "model = keras.Sequential([ \n",
        "    keras.layers.Flatten(input_shape=(28, 28)), # (28,28) mean image are 28 by 28 size\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu), # this middle layer is called hidden layer, having 128 neurons\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax) # 10 mean 10 neurons b/c 10 classess of clothing in dataset\n",
        "])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CheGt5hKd8tv"
      },
      "source": [
        "## complete code for creating neurall network for giving basic computer vision capability to recognizing different items of clothng\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3vUgE67C3S"
      },
      "source": [
        "\n",
        "# the MNIST datset is available directly in tf.keras datasets API. you load it likethis\n",
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOQB2vb1DM2p"
      },
      "source": [
        "# training and testing values for graphics that contain handwritten digits and their labels (i.e this image contain '1', this image contain '2' etc)\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o3fHO5kAb9Rd",
        "outputId": "77c83ecb-5b8a-4fdc-b641-2229a912d84d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print('Training Label:', training_labels[0])\n",
        "print('Trainig Image:', training_images[0])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label: 9\n",
            "Trainig Image: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKZD8ov7dmb4"
      },
      "source": [
        "# greyscale image values are 0-255\n",
        "\n",
        "# neural network work better with normalize data\n",
        "# for normalization every value divided by 255\n",
        "# after normalization every value is between 0-1\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55ZD9P08fUmZ"
      },
      "source": [
        "# desiging the model\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                   tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# Sequential: define a SEQUENCES of layers in neural network\n",
        "# Flatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into 1 dimensional set.\n",
        "# Flatten: used to transfer the data into 1 dimention b/c we can't pass the columns to neural network algorithm.\n",
        "# Dense: Adds a layer of neurons  \"OR\" Dense layer connect input layer to output layer\n",
        "# Dense layer: have neurons (in this 128 neurons) and activation function\n",
        "# output layer will also be Dense layer(10, activation function is softmax), 10 means 10 layers b/c our target variable y has 10 levels.\n",
        "# Each layer of neurons need a 'Activation Function' to tell them what to do. There's lot of options, but use these for now.\n",
        "# Relu: effectively mean \"if X>0 return X else return 0\" - it only passes values 0 or greater to the next layer in the network.\n",
        "# Softmax: takes a set of values, and effectively pick the biggest one.\n",
        "\n",
        "# There are 3 layers\n",
        "# an input layer in the shape of the data.\n",
        "# an output layer in the shape of the classes.\n",
        "# one hidden layer that tries to figure out the roles between them."
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzj7JbHcivLw",
        "outputId": "d49c03bc-0563-4846-bc28-e9d06f3df3e8"
      },
      "source": [
        "# compiling model with optimizer and loss function\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "# Optimizer: for new guess (use the optimizer to generate a new guess and repeat).\n",
        "# Loss: measure how well or how badly it did (mean how well or badly optimizer's guess) \n",
        "# Goal of these functions is to make a guess as to what the relationship is between the input data and the output data\n",
        "\n",
        "\n",
        "# training model\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4957\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3755\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3366\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3158\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50a3411590>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahknnydqbJDL"
      },
      "source": [
        "# in upper, Loss: 0.2948 mean neural network is 71% accurate in classifying the training data. i.e, it figured out a pattern between the image and the labels that worked 71% of the time. not good, but not so bad considering it was onlt trained for 5 epochs and done quite quickly."
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdkAXuA-iwGf",
        "outputId": "ba2408af-5f99-487b-c751-8ef30121100b"
      },
      "source": [
        "# we have test images for unseen data. Pass 2 sets to evaluate module, and it will report back loss for each.\n",
        "\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3530\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3530004918575287"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIy0itrZWAP1"
      },
      "source": [
        "# 0.35 mean 35% error and 65% accuracy"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50d1ZeZpeCm_"
      },
      "source": [
        "## Again code for practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "4ABPCcAwY1Wh",
        "outputId": "04f4acf8-cb2f-4a6a-8606-e7fca326d5ce"
      },
      "source": [
        "mnuist2 = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWXJCBw0e-au",
        "outputId": "a3a0429b-c5a9-4d64-c413-fa137d3e01de"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "print('Loss/Error:', model.evaluate(test_images, test_labels))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4983\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3741\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3380\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3145\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2936\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3377\n",
            "Loss/Error: 0.3377010226249695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJI272MuiQsL"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hb3RPphhFaG",
        "outputId": "a8307982-0a71-40bf-dc94-1d7ca4b394d4"
      },
      "source": [
        "classification = model.predict(test_images)\n",
        "classification"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1913834e-06, 2.7264002e-07, 5.0542610e-07, ..., 8.5956328e-02,\n",
              "        1.0914909e-05, 9.1202050e-01],\n",
              "       [1.1846575e-04, 6.0507586e-09, 9.7598040e-01, ..., 2.4106930e-10,\n",
              "        1.6193613e-06, 1.7137735e-09],\n",
              "       [1.1862641e-06, 9.9999833e-01, 5.5015111e-08, ..., 2.7211185e-16,\n",
              "        6.6610389e-10, 6.7063537e-15],\n",
              "       ...,\n",
              "       [6.4848969e-04, 8.4885245e-09, 1.2727143e-04, ..., 3.4795053e-06,\n",
              "        9.9845648e-01, 2.3885673e-07],\n",
              "       [8.0761072e-07, 9.9995291e-01, 9.0543477e-07, ..., 4.4906448e-10,\n",
              "        5.1309677e-08, 1.1351671e-08],\n",
              "       [2.1730062e-04, 4.2912732e-05, 3.3178704e-04, ..., 8.1419840e-02,\n",
              "        7.3719695e-03, 1.2733454e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN1QlFocu0KA",
        "outputId": "40f48c74-fe54-4468-f383-3dc469a22857"
      },
      "source": [
        "print(classification[0])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1913834e-06 2.7264002e-07 5.0542610e-07 2.7849410e-08 3.6984216e-07\n",
            " 2.0067636e-03 3.1777008e-06 8.5956328e-02 1.0914909e-05 9.1202050e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90jq0-dqJO8o"
      },
      "source": [
        "#The output of the model is a list of 10 numbers. These numbers are a probability that the value being classified is the corresponding value (https://github.com/zalandoresearch/fashion-mnist#labels), i.e. the first value in the list is the probability that the image is of a '0' (T-shirt/top), the next is a '1' (Trouser) etc\n",
        "#Notice that they are all VERY LOW probabilities.\n",
        "\n",
        "#For index 9 (Ankle boot), the probability was in the 90's, i.e. the neural network is telling us that the image is most likely an ankle boot.\n",
        "\n",
        "# in easy word first one is less match to predicted one & the last one is most likely to predicted."
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTbvZ_AlvEhQ",
        "outputId": "73bfb6b1-2c77-4db9-ee1e-b67513051147"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUBM6E83vxxS"
      },
      "source": [
        "# Labels \n",
        "\n",
        "# Label | Description\n",
        "# 0\t    | T-shirt/top\n",
        "# 1 \t  | Trouser\n",
        "# 2\t    |\tPullover\n",
        "# 3\t    |\tDress\n",
        "# 4\t    |\tCoat\n",
        "# 5\t    |\tSandal\n",
        "# 6\t    |\tShirt\n",
        "# 7\t    |\tSneaker\n",
        "# 8\t    |\tBag\n",
        "# 9\t    |\tAnkle boot"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "KjlIXz4A_WHM",
        "outputId": "fda10375-b974-4d9a-b750-0f519b531187"
      },
      "source": [
        "# rough work (for understanding/for myself)\n",
        "plt.imshow(test_images[0])\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f50a0893ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E77Y5NKMMe3l",
        "outputId": "debcbe13-910d-4afa-b75e-2445e8b28cc3"
      },
      "source": [
        "print(classification[42])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.23151049e-01 1.39450282e-02 1.23202950e-02 4.28367555e-01\n",
            " 1.28776252e-01 2.10423892e-07 2.88390756e-01 1.01268945e-07\n",
            " 5.04789175e-03 7.91498792e-07]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbXrd9lEMpQ9",
        "outputId": "dfae65f7-3a71-45c6-eecb-14dd13279a63"
      },
      "source": [
        "print(test_labels[42])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jeK9lJ4yMv3D",
        "outputId": "a9eaeb6e-d2c7-4e5a-89a1-f2971e6086f2"
      },
      "source": [
        "plt.imshow(test_images[7])\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f50a0852790>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fFs6wxoNejb"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhN3C43xM4sT",
        "outputId": "180b582b-03d4-4cd8-a388-937cd611f207"
      },
      "source": [
        "# Question: Increase to 1024 Neurons -- What's the impact?\n",
        "# Answer: Training takes longer, but is more accurate\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), # Try experimenting with this layer\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1877\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0747\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0498\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0333\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0258\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0715\n",
            "[7.1219336e-10 4.3370019e-09 3.3518296e-07 5.1561392e-06 2.8627963e-13\n",
            " 4.1334975e-09 1.2162046e-13 9.9999428e-01 9.5129927e-08 1.6346374e-07]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4dB7QCZJvw5",
        "outputId": "89920ec4-b88b-406a-b04c-4dccd3f79c89"
      },
      "source": [
        "# prediction\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag',\t'Ankle boot']\n",
        "\n",
        "Prediction = model.predict(test_images)\n",
        "\n",
        "print(Prediction[0])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9807\n",
            "[3.2095301e-14 2.2463021e-12 1.1580813e-11 2.3241728e-06 3.7355867e-19\n",
            " 4.6495110e-11 3.7880129e-16 9.9999774e-01 6.9226125e-11 7.2828588e-10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R4O0HYCLYqu",
        "outputId": "5167bb81-6aab-434b-8230-322c1fa8f959"
      },
      "source": [
        "# getting maximum number b/c maximum number is highest probability (more likely)\n",
        "print(np.argmax(Prediction[0]))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s-WJxSVMEwX"
      },
      "source": [
        "# 7 was a sneaker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxusr5T4L83t",
        "outputId": "fee689c8-6c94-4902-8e07-8ac76477ffbe"
      },
      "source": [
        "# getting directly name\n",
        "print('Most likely to:', class_names[np.argmax(Prediction[0])])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most likely to: Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqYg6d-QQINI"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6GD3lPHN9Ym",
        "outputId": "5f9cc011-1dc3-4edc-90b0-c5d93a9e24a6"
      },
      "source": [
        "# Consider the impact of training for more or less epochs. Why do you think that would be the case?¶\n",
        "# Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
        "# Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases.\n",
        "#This is a side effect of something called 'overfitting' which you can learn about later and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2611\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1114\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0754\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0570\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0443\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0335\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0277\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0215\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0144\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0126\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0097\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0080\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0078\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0074\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0064\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0056\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0053\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0055\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0038\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0062\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0048\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0036\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0044\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0038\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0027\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1212\n",
            "[7.22236014e-20 1.52733048e-18 2.23669014e-10 5.00595077e-09\n",
            " 2.28611038e-28 1.23995445e-26 1.16710046e-29 1.00000000e+00\n",
            " 1.74371653e-15 2.48623340e-18]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGb-Y_ubrytn",
        "outputId": "87384a5c-c08a-4349-fa83-ca08dac70687"
      },
      "source": [
        "def printFun(test):\n",
        "\n",
        "  if(test<1):\n",
        "    return\n",
        "  else:\n",
        "\n",
        "    print(test, end=\" \")\n",
        "    printFun(test-1)\n",
        "    print(test, end=\" \")\n",
        "    return\n",
        "printFun(4)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 3 2 1 1 2 3 4 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzsBV8UHV6pF"
      },
      "source": [
        "## Using callbacks to control training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITobRUYxsTmf",
        "outputId": "f4522177-dffb-4a81-947c-2035c1dc3d4c"
      },
      "source": [
        "# defining class to handle callback\n",
        "class mycallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print('\\n Reached 90% acuuracy so cancelling training!')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# intiate callback class itself\n",
        "callbacks = mycallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                   tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callbacks]) # set up callback in training"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4724 - accuracy: 0.8316\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3562 - accuracy: 0.8691\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3221 - accuracy: 0.8821\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2977 - accuracy: 0.8890\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2809 - accuracy: 0.8953\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2648 - accuracy: 0.9012\n",
            "\n",
            " Reached 90% acuuracy so cancelling training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50a068ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWYPDX0EuALE",
        "outputId": "4c19974f-4328-49bd-f947-51dd2464b30d"
      },
      "source": [
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "classification = model.predict(x_test)\n",
        "print('\\n', classification[45])\n",
        "print('Actual:', y_test[45])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8843\n",
            "\n",
            " [2.9134872e-05 9.1329144e-07 3.1878885e-06 8.6886803e-07 1.7601602e-06\n",
            " 1.7100057e-02 6.6792377e-06 8.9934844e-01 3.2825828e-05 8.3476193e-02]\n",
            "Actual: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6pxRyE2kAW"
      },
      "source": [
        "# in upper output actual is 7(sneaker) and predicted is also 7.340, prediction goes accurate at end (from 6.17 - 7.340), mean 45 is like 7"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPwAdSUb8emz"
      },
      "source": [
        "## Assignment: 2 Implement a Deep Neural Network to recognize handwritten digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "NPYng5Dl9-Yx",
        "outputId": "afab2f0d-e06a-4e18-968d-ba32f851ef49"
      },
      "source": [
        "# Loading the MNIST dataset in keras\n",
        "# plot ad hoc mnist instances\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[54], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[39])\n",
        "plt.show()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlHBXHUo3UVE",
        "outputId": "1f1f544e-6f37-4e9b-c66b-28e667d4af9b"
      },
      "source": [
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# X_test (mean test_images), y_test (mean test_labels), X_train (mean training_images) and y_train (mean train_labels)\n",
        "\n",
        "# Normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "# build the model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                             tf.keras.layers.Dense(128, activation='relu'),\n",
        "                             tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2648 - accuracy: 0.9253\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1134 - accuracy: 0.9664\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0772 - accuracy: 0.9769\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0567 - accuracy: 0.9826\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0438 - accuracy: 0.9865\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0339 - accuracy: 0.9895\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0280 - accuracy: 0.9911\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9935\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0180 - accuracy: 0.9946\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0141 - accuracy: 0.9960\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0126 - accuracy: 0.9961\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0105 - accuracy: 0.9969\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0096 - accuracy: 0.9971\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0081 - accuracy: 0.9975\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0077 - accuracy: 0.9976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f50a048ced0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0jyBHcsCtmV",
        "outputId": "8ad57ea3-1201-4865-a3ab-a1890ff48407"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('\\nTest Loss:', test_loss)\n",
        "print('\\nTest Accuracy:', test_acc)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9807\n",
            "\n",
            "Test Loss: 0.08261347562074661\n",
            "\n",
            "Test Accuracy: 0.9807000160217285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Na4eeg9CGcg"
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_R5598lDMea",
        "outputId": "044bd566-1312-4cf3-d344-b0841f136d16"
      },
      "source": [
        "print(prediction[943])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.3780967e-08 9.0962134e-13 1.5444404e-12 1.7551586e-15 4.6744997e-11\n",
            " 1.6204953e-06 9.9999821e-01 3.8631651e-14 8.3306510e-08 3.6507012e-13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_VfwTmBHnAg"
      },
      "source": [
        "# from upper 10 numbers array (10 predicted values) the answer is highest value"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i6SKRPhH2y2",
        "outputId": "fcacb922-d446-4743-fa1e-daa94fd7fa2e"
      },
      "source": [
        "# or directly get largest value \n",
        "print(np.argmax(prediction[943]))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeyZUh-iQoQg",
        "outputId": "431ad3f8-106b-4f62-8dfc-cb2917f1340d"
      },
      "source": [
        "print('Most likely to:', np.argmax(prediction[943]))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most likely to: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ejHh83_18I4t",
        "outputId": "f925acc8-a650-40af-cddd-c482a33099f2"
      },
      "source": [
        "plt.imshow(X_test[943])"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5099da9ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQAueuS2APa2",
        "outputId": "e6714fc8-9de6-44b6-a359-80a4c437652b"
      },
      "source": [
        "print('Test image label:',y_test[943])"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test image label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHvqLblVBV0M"
      },
      "source": [
        ""
      ],
      "execution_count": 124,
      "outputs": []
    }
  ]
}